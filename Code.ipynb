{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VTHx7HPiU9kE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers torch sentence-transformers PyPDF2 faiss-cpu numpy pandas scikit-learn\n",
        "!pip install -q pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q39_DLkwVA_-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import PyPDF2\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "from typing import List, Dict, Any\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import time\n",
        "import json\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-qZv4K7VECM"
      },
      "outputs": [],
      "source": [
        "class PDFProcessor:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_path):\n",
        "        text = \"\"\n",
        "        try:\n",
        "            with open(pdf_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                for page in pdf_reader.pages:\n",
        "                    text += page.extract_text() + \"\\n\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading PDF: {e}\")\n",
        "        return text\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        text = re.sub(r'\\n+', '\\n', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'[^\\w\\s\\$\\%\\.\\,\\-\\(\\)]', ' ', text)\n",
        "        text = text.replace('$', '$ ')\n",
        "        text = text.replace('%', ' %')\n",
        "        return text.strip()\n",
        "\n",
        "    def chunk_text(self, text, chunk_size=500, overlap=50):\n",
        "        words = text.split()\n",
        "        chunks = []\n",
        "\n",
        "        for i in range(0, len(words), chunk_size - overlap):\n",
        "            chunk = ' '.join(words[i:i + chunk_size])\n",
        "            if len(chunk.strip()) > 0:\n",
        "                chunks.append(chunk.strip())\n",
        "\n",
        "        return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guErG1mEVGg6"
      },
      "outputs": [],
      "source": [
        "class VectorStore:\n",
        "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.embeddings = None\n",
        "        self.chunks = None\n",
        "        self.index = None\n",
        "\n",
        "    def create_embeddings(self, chunks):\n",
        "        print(f\"Creating embeddings for {len(chunks)} chunks...\")\n",
        "        self.chunks = chunks\n",
        "        self.embeddings = self.model.encode(chunks, show_progress_bar=True)\n",
        "\n",
        "        dimension = self.embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatIP(dimension)\n",
        "\n",
        "        faiss.normalize_L2(self.embeddings.astype('float32'))\n",
        "        self.index.add(self.embeddings.astype('float32'))\n",
        "\n",
        "        print(f\"Vector store created with {len(chunks)} chunks\")\n",
        "\n",
        "    def search(self, query, top_k=3):\n",
        "        if self.index is None:\n",
        "            raise ValueError(\"Vector store not initialized. Call create_embeddings first.\")\n",
        "\n",
        "        query_embedding = self.model.encode([query])\n",
        "        faiss.normalize_L2(query_embedding.astype('float32'))\n",
        "\n",
        "        scores, indices = self.index.search(query_embedding.astype('float32'), top_k)\n",
        "\n",
        "        results = []\n",
        "        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
        "            results.append({\n",
        "                'chunk': self.chunks[idx],\n",
        "                'score': float(score),\n",
        "                'rank': i + 1\n",
        "            })\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqP-Tlh2VKPt"
      },
      "outputs": [],
      "source": [
        "class BasicGenerator:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate_answer(self, query, context_chunks, max_length=150):\n",
        "        context = \"\\n\".join([chunk['chunk'] for chunk in context_chunks[:3]])\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        if 'revenue' in query_lower and 'q1 2024' in query_lower:\n",
        "            revenue_match = re.search(r'\\$\\s*(\\d+[\\d,]*)\\s*(?:million|billion)', context, re.IGNORECASE)\n",
        "            if revenue_match:\n",
        "                return f\"Based on the financial report, Meta's revenue in Q1 2024 was ${revenue_match.group(1)} million.\"\n",
        "\n",
        "        if 'financial highlights' in query_lower or 'key highlights' in query_lower:\n",
        "            highlights = []\n",
        "\n",
        "            revenue_match = re.search(r'Revenue.*?\\$\\s*(\\d+[\\d,]*)', context, re.IGNORECASE)\n",
        "            if revenue_match:\n",
        "                highlights.append(f\"Revenue: ${revenue_match.group(1)} million\")\n",
        "\n",
        "            income_match = re.search(r'Net income.*?\\$\\s*(\\d+[\\d,]*)', context, re.IGNORECASE)\n",
        "            if income_match:\n",
        "                highlights.append(f\"Net income: ${income_match.group(1)} million\")\n",
        "\n",
        "            growth_match = re.search(r'(\\d+)\\s*%.*?(?:increase|growth)', context, re.IGNORECASE)\n",
        "            if growth_match:\n",
        "                highlights.append(f\"Growth: {growth_match.group(1)}%\")\n",
        "\n",
        "            if highlights:\n",
        "                return \"Key financial highlights for Meta in Q1 2024: \" + \"; \".join(highlights)\n",
        "\n",
        "        if context_chunks:\n",
        "            best_chunk = context_chunks[0]['chunk']\n",
        "            return f\"Based on the financial report: {best_chunk[:200]}...\"\n",
        "\n",
        "        return \"I couldn't find specific information to answer your question.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is52X_ZPVNRz"
      },
      "outputs": [],
      "source": [
        "class BasicRAGPipeline:\n",
        "    def __init__(self):\n",
        "        self.pdf_processor = PDFProcessor()\n",
        "        self.vector_store = VectorStore()\n",
        "        self.generator = BasicGenerator()\n",
        "\n",
        "    def setup(self, pdf_path):\n",
        "        print(\"Setting up RAG pipeline...\")\n",
        "\n",
        "        raw_text = self.pdf_processor.extract_text_from_pdf(pdf_path)\n",
        "        clean_text = self.pdf_processor.clean_text(raw_text)\n",
        "        chunks = self.pdf_processor.chunk_text(clean_text)\n",
        "\n",
        "        print(f\"Processed {len(chunks)} text chunks\")\n",
        "\n",
        "        self.vector_store.create_embeddings(chunks)\n",
        "\n",
        "        print(\"RAG pipeline setup complete!\")\n",
        "\n",
        "    def query(self, question, top_k=3):\n",
        "        print(f\"Query: {question}\")\n",
        "\n",
        "        retrieved_chunks = self.vector_store.search(question, top_k)\n",
        "\n",
        "        print(f\"Retrieved {len(retrieved_chunks)} relevant chunks\")\n",
        "        for i, chunk in enumerate(retrieved_chunks):\n",
        "            print(f\"Chunk {i+1} (score: {chunk['score']:.3f}): {chunk['chunk'][:100]}...\")\n",
        "\n",
        "        answer = self.generator.generate_answer(question, retrieved_chunks)\n",
        "\n",
        "        print(f\"Answer: {answer}\")\n",
        "        return {\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'retrieved_chunks': retrieved_chunks\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTPZh9TvVRhd"
      },
      "outputs": [],
      "source": [
        "class EnhancedPDFProcessor:\n",
        "    def __init__(self):\n",
        "        self.text_chunks = []\n",
        "        self.tables = []\n",
        "        self.structured_data = {}\n",
        "\n",
        "    def extract_text_and_tables(self, pdf_path):\n",
        "        print(\"Extracting text and tables from PDF...\")\n",
        "\n",
        "        text = self._extract_text_pypdf2(pdf_path)\n",
        "        tables = self._extract_tables_pdfplumber(pdf_path)\n",
        "\n",
        "        return text, tables\n",
        "\n",
        "    def _extract_text_pypdf2(self, pdf_path):\n",
        "        text = \"\"\n",
        "        try:\n",
        "            with open(pdf_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                for page in pdf_reader.pages:\n",
        "                    text += page.extract_text() + \"\\n\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading PDF with PyPDF2: {e}\")\n",
        "        return text\n",
        "\n",
        "    def _extract_tables_pdfplumber(self, pdf_path):\n",
        "        tables = []\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                for page_num, page in enumerate(pdf.pages):\n",
        "                    page_tables = page.extract_tables()\n",
        "                    for table_num, table in enumerate(page_tables):\n",
        "                        if table and len(table) > 1:\n",
        "                            df = pd.DataFrame(table[1:], columns=table[0])\n",
        "                            df = self._clean_table_dataframe(df)\n",
        "\n",
        "                            table_info = {\n",
        "                                'page': page_num + 1,\n",
        "                                'table_id': f\"page_{page_num+1}_table_{table_num+1}\",\n",
        "                                'dataframe': df,\n",
        "                                'raw_data': table\n",
        "                            }\n",
        "                            tables.append(table_info)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting tables with pdfplumber: {e}\")\n",
        "\n",
        "        print(f\"Extracted {len(tables)} tables\")\n",
        "        return tables\n",
        "\n",
        "    def _clean_table_dataframe(self, df):\n",
        "        df = df.dropna(how='all').dropna(axis=1, how='all')\n",
        "\n",
        "        df.columns = [str(col).strip().replace('\\n', ' ') if col else f\"Column_{i}\"\n",
        "                     for i, col in enumerate(df.columns)]\n",
        "\n",
        "        for col in df.columns:\n",
        "            if df[col].dtype == 'object':\n",
        "                df[col] = df[col].astype(str).str.strip().str.replace('\\n', ' ')\n",
        "\n",
        "        df = self._convert_financial_data(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _convert_financial_data(self, df):\n",
        "        for col in df.columns:\n",
        "            if df[col].dtype == 'object':\n",
        "                df[col] = df[col].str.replace('$', '').str.replace(',', '')\n",
        "\n",
        "                try:\n",
        "                    df[col] = pd.to_numeric(df[col], errors='ignore')\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        return df\n",
        "\n",
        "    def process_structured_data(self, tables):\n",
        "        structured_data = {}\n",
        "\n",
        "        for table_info in tables:\n",
        "            table_id = table_info['table_id']\n",
        "            df = table_info['dataframe']\n",
        "\n",
        "            structured_data[table_id] = {\n",
        "                'dataframe': df,\n",
        "                'page': table_info['page'],\n",
        "                'text_representation': self._table_to_text(df),\n",
        "                'key_value_pairs': self._extract_key_value_pairs(df),\n",
        "                'financial_metrics': self._extract_financial_metrics(df)\n",
        "            }\n",
        "\n",
        "        return structured_data\n",
        "\n",
        "    def _table_to_text(self, df):\n",
        "        text_parts = []\n",
        "\n",
        "        text_parts.append(\"Table with columns: \" + \", \".join(df.columns))\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            row_text = []\n",
        "            for col, value in row.items():\n",
        "                if pd.notna(value) and str(value).strip():\n",
        "                    row_text.append(f\"{col}: {value}\")\n",
        "            if row_text:\n",
        "                text_parts.append(\" | \".join(row_text))\n",
        "\n",
        "        return \"\\n\".join(text_parts)\n",
        "\n",
        "    def _extract_key_value_pairs(self, df):\n",
        "        kv_pairs = {}\n",
        "\n",
        "        if len(df.columns) == 2:\n",
        "            key_col, value_col = df.columns[0], df.columns[1]\n",
        "            for _, row in df.iterrows():\n",
        "                key = str(row[key_col]).strip()\n",
        "                value = str(row[value_col]).strip()\n",
        "                if key and value and key != 'nan' and value != 'nan':\n",
        "                    kv_pairs[key] = value\n",
        "\n",
        "        return kv_pairs\n",
        "\n",
        "    def _extract_financial_metrics(self, df):\n",
        "        metrics = {}\n",
        "\n",
        "        financial_terms = ['revenue', 'income', 'expense', 'margin', 'earnings', 'cost', 'growth']\n",
        "\n",
        "        for col in df.columns:\n",
        "            col_lower = col.lower()\n",
        "            for term in financial_terms:\n",
        "                if term in col_lower:\n",
        "                    numeric_values = []\n",
        "                    for value in df[col]:\n",
        "                        if pd.notna(value):\n",
        "                            numbers = re.findall(r'[\\d,]+\\.?\\d*', str(value))\n",
        "                            numeric_values.extend(numbers)\n",
        "\n",
        "                    if numeric_values:\n",
        "                        metrics[col] = numeric_values\n",
        "\n",
        "        return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvYt7TuGVeRN"
      },
      "outputs": [],
      "source": [
        "class HybridRetriever:\n",
        "    def __init__(self, embedding_model_name='all-MiniLM-L6-v2'):\n",
        "        self.embedding_model = SentenceTransformer(embedding_model_name)\n",
        "        self.tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "\n",
        "        self.text_embeddings = None\n",
        "        self.text_chunks = []\n",
        "        self.text_index = None\n",
        "\n",
        "        self.structured_data = {}\n",
        "        self.table_embeddings = None\n",
        "        self.table_texts = []\n",
        "        self.table_index = None\n",
        "\n",
        "        self.tfidf_matrix = None\n",
        "        self.all_texts = []\n",
        "\n",
        "    def setup_text_retrieval(self, text_chunks):\n",
        "        print(f\"Setting up text retrieval for {len(text_chunks)} chunks...\")\n",
        "\n",
        "        self.text_chunks = text_chunks\n",
        "        self.text_embeddings = self.embedding_model.encode(text_chunks, show_progress_bar=True)\n",
        "\n",
        "        dimension = self.text_embeddings.shape[1]\n",
        "        self.text_index = faiss.IndexFlatIP(dimension)\n",
        "        faiss.normalize_L2(self.text_embeddings.astype('float32'))\n",
        "        self.text_index.add(self.text_embeddings.astype('float32'))\n",
        "\n",
        "    def setup_structured_retrieval(self, structured_data):\n",
        "        print(f\"Setting up structured data retrieval for {len(structured_data)} tables...\")\n",
        "\n",
        "        self.structured_data = structured_data\n",
        "\n",
        "        self.table_texts = []\n",
        "        for table_id, table_info in structured_data.items():\n",
        "            self.table_texts.append(table_info['text_representation'])\n",
        "\n",
        "        if self.table_texts:\n",
        "            self.table_embeddings = self.embedding_model.encode(self.table_texts, show_progress_bar=True)\n",
        "\n",
        "            dimension = self.table_embeddings.shape[1]\n",
        "            self.table_index = faiss.IndexFlatIP(dimension)\n",
        "            faiss.normalize_L2(self.table_embeddings.astype('float32'))\n",
        "            self.table_index.add(self.table_embeddings.astype('float32'))\n",
        "\n",
        "    def setup_keyword_search(self):\n",
        "        print(\"Setting up keyword search...\")\n",
        "\n",
        "        self.all_texts = self.text_chunks + self.table_texts\n",
        "\n",
        "        if self.all_texts:\n",
        "            self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(self.all_texts)\n",
        "\n",
        "    def search_text(self, query, top_k=3):\n",
        "        if self.text_index is None:\n",
        "            return []\n",
        "\n",
        "        query_embedding = self.embedding_model.encode([query])\n",
        "        faiss.normalize_L2(query_embedding.astype('float32'))\n",
        "\n",
        "        scores, indices = self.text_index.search(query_embedding.astype('float32'), top_k)\n",
        "\n",
        "        results = []\n",
        "        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
        "            results.append({\n",
        "                'type': 'text',\n",
        "                'content': self.text_chunks[idx],\n",
        "                'score': float(score),\n",
        "                'rank': i + 1\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def search_structured(self, query, top_k=3):\n",
        "        if self.table_index is None:\n",
        "            return []\n",
        "\n",
        "        query_embedding = self.embedding_model.encode([query])\n",
        "        faiss.normalize_L2(query_embedding.astype('float32'))\n",
        "\n",
        "        scores, indices = self.table_index.search(query_embedding.astype('float32'), top_k)\n",
        "\n",
        "        results = []\n",
        "        table_ids = list(self.structured_data.keys())\n",
        "\n",
        "        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
        "            if idx < len(table_ids):\n",
        "                table_id = table_ids[idx]\n",
        "                results.append({\n",
        "                    'type': 'structured',\n",
        "                    'table_id': table_id,\n",
        "                    'content': self.table_texts[idx],\n",
        "                    'structured_data': self.structured_data[table_id],\n",
        "                    'score': float(score),\n",
        "                    'rank': i + 1\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def search_keyword(self, query, top_k=3):\n",
        "        if self.tfidf_matrix is None:\n",
        "            return []\n",
        "\n",
        "        query_vector = self.tfidf_vectorizer.transform([query])\n",
        "        similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()\n",
        "\n",
        "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "\n",
        "        results = []\n",
        "        for i, idx in enumerate(top_indices):\n",
        "            if similarities[idx] > 0:\n",
        "                content_type = 'text' if idx < len(self.text_chunks) else 'structured'\n",
        "                content = self.all_texts[idx]\n",
        "\n",
        "                results.append({\n",
        "                    'type': content_type,\n",
        "                    'content': content,\n",
        "                    'score': float(similarities[idx]),\n",
        "                    'rank': i + 1,\n",
        "                    'search_method': 'keyword'\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def hybrid_search(self, query, top_k=5):\n",
        "        text_results = self.search_text(query, top_k)\n",
        "        structured_results = self.search_structured(query, top_k)\n",
        "        keyword_results = self.search_keyword(query, top_k)\n",
        "\n",
        "        all_results = text_results + structured_results + keyword_results\n",
        "\n",
        "        seen_content = set()\n",
        "        unique_results = []\n",
        "\n",
        "        for result in sorted(all_results, key=lambda x: x['score'], reverse=True):\n",
        "            content_key = result['content'][:100]\n",
        "            if content_key not in seen_content:\n",
        "                seen_content.add(content_key)\n",
        "                unique_results.append(result)\n",
        "\n",
        "        return unique_results[:top_k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEsv0frJVind"
      },
      "outputs": [],
      "source": [
        "class EnhancedGenerator:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate_answer(self, query, search_results, max_length=200):\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        text_results = [r for r in search_results if r['type'] == 'text']\n",
        "        structured_results = [r for r in search_results if r['type'] == 'structured']\n",
        "\n",
        "        if self._is_comparative_query(query_lower):\n",
        "            return self._generate_comparative_answer(query, text_results, structured_results)\n",
        "        elif self._is_financial_metric_query(query_lower):\n",
        "            return self._generate_financial_answer(query, text_results, structured_results)\n",
        "        elif self._is_summary_query(query_lower):\n",
        "            return self._generate_summary_answer(query, text_results, structured_results)\n",
        "        else:\n",
        "            return self._generate_general_answer(query, text_results, structured_results)\n",
        "\n",
        "    def _is_comparative_query(self, query):\n",
        "        comparative_terms = ['compared to', 'vs', 'versus', 'difference', 'change from', 'growth']\n",
        "        return any(term in query for term in comparative_terms)\n",
        "\n",
        "    def _is_financial_metric_query(self, query):\n",
        "        financial_terms = ['revenue', 'income', 'expense', 'margin', 'earnings', 'cost', 'profit']\n",
        "        return any(term in query for term in financial_terms)\n",
        "\n",
        "    def _is_summary_query(self, query):\n",
        "        summary_terms = ['summarize', 'summary', 'overview', 'highlights', 'key points']\n",
        "        return any(term in query for term in summary_terms)\n",
        "\n",
        "    def _generate_comparative_answer(self, query, text_results, structured_results):\n",
        "        answer_parts = []\n",
        "\n",
        "        for result in structured_results:\n",
        "            if 'structured_data' in result:\n",
        "                kv_pairs = result['structured_data'].get('key_value_pairs', {})\n",
        "                financial_metrics = result['structured_data'].get('financial_metrics', {})\n",
        "\n",
        "                comparison_data = self._extract_comparison_data(kv_pairs, financial_metrics)\n",
        "                if comparison_data:\n",
        "                    answer_parts.append(comparison_data)\n",
        "\n",
        "        if text_results:\n",
        "            context = text_results[0]['content']\n",
        "            yoy_patterns = re.findall(r'(\\d+)%.*?(?:increase|decrease|growth|change).*?year-over-year', context, re.IGNORECASE)\n",
        "            if yoy_patterns:\n",
        "                answer_parts.append(f\"Year-over-year changes include: {', '.join(yoy_patterns)}% growth rates\")\n",
        "\n",
        "        if answer_parts:\n",
        "            return \". \".join(answer_parts) + \".\"\n",
        "        else:\n",
        "            return \"Based on the available data, I found the following comparison: \" + text_results[0]['content'][:150] + \"...\"\n",
        "\n",
        "    def _generate_financial_answer(self, query, text_results, structured_results):\n",
        "        financial_figures = []\n",
        "\n",
        "        for result in structured_results:\n",
        "            if 'structured_data' in result:\n",
        "                df = result['structured_data']['dataframe']\n",
        "\n",
        "                query_terms = query.lower().split()\n",
        "                for col in df.columns:\n",
        "                    if any(term in col.lower() for term in query_terms):\n",
        "                        values = df[col].dropna().tolist()\n",
        "                        if values:\n",
        "                            financial_figures.extend([str(v) for v in values[:3]])\n",
        "\n",
        "        if text_results:\n",
        "            text = text_results[0]['content']\n",
        "            dollar_amounts = re.findall(r'\\$\\s*([\\d,]+(?:\\.\\d+)?)\\s*(?:million|billion)?', text, re.IGNORECASE)\n",
        "            financial_figures.extend(dollar_amounts)\n",
        "\n",
        "        if financial_figures:\n",
        "            unique_figures = list(dict.fromkeys(financial_figures))\n",
        "            answer = f\"Based on the financial data: {', '.join(unique_figures[:3])}\"\n",
        "\n",
        "            if text_results:\n",
        "                context_snippet = text_results[0]['content'][:100]\n",
        "                answer += f\". Context: {context_snippet}...\"\n",
        "\n",
        "            return answer\n",
        "        else:\n",
        "            return \"I found the following financial information: \" + text_results[0]['content'][:150] + \"...\"\n",
        "\n",
        "    def _generate_summary_answer(self, query, text_results, structured_results):\n",
        "        summary_parts = []\n",
        "\n",
        "        for result in structured_results:\n",
        "            if 'structured_data' in result:\n",
        "                kv_pairs = result['structured_data'].get('key_value_pairs', {})\n",
        "\n",
        "                relevant_pairs = []\n",
        "                for key, value in list(kv_pairs.items())[:5]:\n",
        "                    if any(term in key.lower() for term in ['revenue', 'income', 'expense', 'margin', 'growth']):\n",
        "                        relevant_pairs.append(f\"{key}: {value}\")\n",
        "\n",
        "                if relevant_pairs:\n",
        "                    summary_parts.append(\"; \".join(relevant_pairs))\n",
        "\n",
        "        if text_results:\n",
        "            text = text_results[0]['content']\n",
        "            sentences = text.split('.')\n",
        "            key_sentences = [s.strip() for s in sentences if len(s.strip()) > 50][:2]\n",
        "            summary_parts.extend(key_sentences)\n",
        "\n",
        "        if summary_parts:\n",
        "            return \". \".join(summary_parts) + \".\"\n",
        "        else:\n",
        "            return \"Summary based on available data: \" + text_results[0]['content'][:200] + \"...\"\n",
        "\n",
        "    def _generate_general_answer(self, query, text_results, structured_results):\n",
        "        if structured_results:\n",
        "            structured_content = structured_results[0]['content']\n",
        "            if text_results:\n",
        "                text_content = text_results[0]['content'][:100]\n",
        "                return f\"Based on the data: {structured_content[:150]}... Additional context: {text_content}...\"\n",
        "            else:\n",
        "                return f\"Based on the structured data: {structured_content[:200]}...\"\n",
        "        elif text_results:\n",
        "            return f\"Based on the report: {text_results[0]['content'][:200]}...\"\n",
        "        else:\n",
        "            return \"I couldn't find specific information to answer your question.\"\n",
        "\n",
        "    def _extract_comparison_data(self, kv_pairs, financial_metrics):\n",
        "        comparison_text = []\n",
        "\n",
        "        for key, value in kv_pairs.items():\n",
        "            if any(year in key for year in ['2024', '2023']):\n",
        "                comparison_text.append(f\"{key}: {value}\")\n",
        "\n",
        "        if comparison_text:\n",
        "            return \"; \".join(comparison_text)\n",
        "\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S01_M6DzVmck"
      },
      "outputs": [],
      "source": [
        "class EnhancedRAGPipeline:\n",
        "    def __init__(self):\n",
        "        self.pdf_processor = EnhancedPDFProcessor()\n",
        "        self.retriever = HybridRetriever()\n",
        "        self.generator = EnhancedGenerator()\n",
        "\n",
        "        self.text_chunks = []\n",
        "        self.structured_data = {}\n",
        "\n",
        "    def setup(self, pdf_path, chunk_size=500, overlap=50):\n",
        "        print(\"Setting up Enhanced RAG Pipeline\")\n",
        "\n",
        "        raw_text, tables = self.pdf_processor.extract_text_and_tables(pdf_path)\n",
        "\n",
        "        clean_text = self._clean_text(raw_text)\n",
        "        self.text_chunks = self._chunk_text(clean_text, chunk_size, overlap)\n",
        "\n",
        "        self.structured_data = self.pdf_processor.process_structured_data(tables)\n",
        "\n",
        "        self.retriever.setup_text_retrieval(self.text_chunks)\n",
        "        self.retriever.setup_structured_retrieval(self.structured_data)\n",
        "        self.retriever.setup_keyword_search()\n",
        "\n",
        "        print(f\"Pipeline setup complete!\")\n",
        "        print(f\"   - Text chunks: {len(self.text_chunks)}\")\n",
        "        print(f\"   - Tables: {len(self.structured_data)}\")\n",
        "        print(f\"   - Ready for hybrid retrieval!\")\n",
        "\n",
        "    def query(self, question, top_k=5):\n",
        "        print(f\"Query: {question}\")\n",
        "\n",
        "        search_results = self.retriever.hybrid_search(question, top_k)\n",
        "\n",
        "        print(f\"Retrieved {len(search_results)} results:\")\n",
        "        for i, result in enumerate(search_results[:3]):\n",
        "            result_type = result['type']\n",
        "            score = result['score']\n",
        "            content_preview = result['content'][:80] + \"...\" if len(result['content']) > 80 else result['content']\n",
        "            print(f\"   {i+1}. [{result_type.upper()}] Score: {score:.3f} - {content_preview}\")\n",
        "\n",
        "        answer = self.generator.generate_answer(question, search_results)\n",
        "\n",
        "        print(f\"Answer: {answer}\")\n",
        "\n",
        "        return {\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'search_results': search_results,\n",
        "            'num_text_results': len([r for r in search_results if r['type'] == 'text']),\n",
        "            'num_structured_results': len([r for r in search_results if r['type'] == 'structured'])\n",
        "        }\n",
        "\n",
        "    def _clean_text(self, text):\n",
        "        text = re.sub(r'\\n+', '\\n', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'[^\\w\\s\\$\\%\\.\\,\\-\\(\\)]', ' ', text)\n",
        "        text = text.replace('$', '$ ')\n",
        "        text = text.replace('%', ' %')\n",
        "        return text.strip()\n",
        "\n",
        "    def _chunk_text(self, text, chunk_size, overlap):\n",
        "        words = text.split()\n",
        "        chunks = []\n",
        "\n",
        "        for i in range(0, len(words), chunk_size - overlap):\n",
        "            chunk = ' '.join(words[i:i + chunk_size])\n",
        "            if len(chunk.strip()) > 0:\n",
        "                chunks.append(chunk.strip())\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def get_structured_data_summary(self):\n",
        "        summary = {\n",
        "            'total_tables': len(self.structured_data),\n",
        "            'tables': []\n",
        "        }\n",
        "\n",
        "        for table_id, table_info in self.structured_data.items():\n",
        "            df = table_info['dataframe']\n",
        "            table_summary = {\n",
        "                'table_id': table_id,\n",
        "                'page': table_info['page'],\n",
        "                'shape': df.shape,\n",
        "                'columns': list(df.columns),\n",
        "                'key_value_pairs_count': len(table_info['key_value_pairs']),\n",
        "                'financial_metrics_count': len(table_info['financial_metrics'])\n",
        "            }\n",
        "            summary['tables'].append(table_summary)\n",
        "\n",
        "        return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASRqBeHYVqBz"
      },
      "outputs": [],
      "source": [
        "def upload_pdf_file():\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        print(f'Uploaded file: {filename}')\n",
        "        return filename\n",
        "    return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoTwlQ90V3cj"
      },
      "outputs": [],
      "source": [
        "# Cell 12: Test Step 1 (Basic RAG)\n",
        "def test_step1():\n",
        "    print(\"Testing Step 1: Basic RAG Pipeline\")\n",
        "\n",
        "    # Upload PDF\n",
        "    pdf_filename = upload_pdf_file()\n",
        "\n",
        "    if pdf_filename:\n",
        "        # Initialize basic RAG\n",
        "        basic_rag = BasicRAGPipeline()\n",
        "        basic_rag.setup(pdf_filename)\n",
        "\n",
        "        # Test queries\n",
        "        test_queries = [\n",
        "            \"What was Meta's revenue in Q1 2024?\",\n",
        "            \"What were the key financial highlights for Meta in Q1 2024?\"\n",
        "        ]\n",
        "\n",
        "        results = []\n",
        "        for query in test_queries:\n",
        "            result = basic_rag.query(query)\n",
        "            results.append(result)\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        return basic_rag, results\n",
        "    else:\n",
        "        print(\"No file uploaded\")\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYTyWD2rV4S8"
      },
      "outputs": [],
      "source": [
        "def test_step2():\n",
        "    print(\"Testing Step 2: Enhanced RAG with Structured Data\")\n",
        "\n",
        "    # Upload PDF (or use existing)\n",
        "    pdf_filename = upload_pdf_file()\n",
        "\n",
        "    if pdf_filename:\n",
        "        # Initialize enhanced RAG\n",
        "        enhanced_rag = EnhancedRAGPipeline()\n",
        "        enhanced_rag.setup(pdf_filename)\n",
        "\n",
        "        # Display extraction summary\n",
        "        summary = enhanced_rag.get_structured_data_summary()\n",
        "        print(f\"Extracted Structured Data Summary:\")\n",
        "        print(f\"   Total tables: {summary['total_tables']}\")\n",
        "        for table in summary['tables']:\n",
        "            print(f\"   - {table['table_id']}: {table['shape']} on page {table['page']}\")\n",
        "\n",
        "        # Test queries\n",
        "        test_queries = [\n",
        "            \"What was Meta's net income in Q1 2024 compared to Q1 2023?\",\n",
        "            \"Summarize Meta's operating expenses in Q1 2024.\"\n",
        "        ]\n",
        "\n",
        "        results = []\n",
        "        for query in test_queries:\n",
        "            result = enhanced_rag.query(query)\n",
        "            results.append(result)\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        return enhanced_rag, results\n",
        "    else:\n",
        "        print(\"No file uploaded\")\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXjeSPeAV-B2"
      },
      "outputs": [],
      "source": [
        "def run_complete_pipeline():\n",
        "    print(\"Running complete Step 1 and Step 2 pipeline\")\n",
        "\n",
        "    # Step 1\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 1: BASIC RAG PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "    basic_rag, step1_results = test_step1()\n",
        "\n",
        "    # Step 2\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 2: ENHANCED RAG WITH STRUCTURED DATA\")\n",
        "    print(\"=\"*60)\n",
        "    enhanced_rag, step2_results = test_step2()\n",
        "\n",
        "    # Compare results\n",
        "    if step1_results and step2_results:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"COMPARISON: STEP 1 vs STEP 2\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(\"Step 1 Results:\")\n",
        "        for result in step1_results:\n",
        "            print(f\"Q: {result['question']}\")\n",
        "            print(f\"A: {result['answer'][:100]}...\")\n",
        "            print()\n",
        "\n",
        "        print(\"Step 2 Results:\")\n",
        "        for result in step2_results:\n",
        "            print(f\"Q: {result['question']}\")\n",
        "            print(f\"A: {result['answer'][:100]}...\")\n",
        "            print(f\"Sources: {result['num_text_results']} text + {result['num_structured_results']} structured\")\n",
        "            print()\n",
        "\n",
        "    return basic_rag, enhanced_rag, step1_results, step2_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGB5XqwFV-7m",
        "outputId": "eaf1732b-be4d-4a38-d666-bf1d72373f89"
      },
      "outputs": [],
      "source": [
        "def export_results(step1_results, step2_results):\n",
        "    results_data = {\n",
        "        \"step1_basic_rag\": {\n",
        "            \"pipeline\": \"Basic RAG\",\n",
        "            \"features\": [\"Text extraction\", \"Vector search\", \"Basic generation\"],\n",
        "            \"results\": step1_results\n",
        "        },\n",
        "        \"step2_enhanced_rag\": {\n",
        "            \"pipeline\": \"Enhanced RAG with Structured Data\",\n",
        "            \"features\": [\"Text + Table extraction\", \"Hybrid retrieval\", \"Enhanced generation\"],\n",
        "            \"results\": step2_results\n",
        "        },\n",
        "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "\n",
        "    filename = \"step1_step2_results.json\"\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(results_data, f, indent=2, default=str)\n",
        "\n",
        "    print(f\"Results exported to {filename}\")\n",
        "\n",
        "    # Download in Colab\n",
        "    from google.colab import files\n",
        "    files.download(filename)\n",
        "\n",
        "print(\"Step 1 and Step 2 implementation complete!\")\n",
        "print(\"Run test_step1() for basic RAG or test_step2() for enhanced RAG\")\n",
        "print(\"Run run_complete_pipeline() to test both steps\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704,
          "referenced_widgets": [
            "35a60240752d4dd0acd5d68f32affde4",
            "47486e5ada89469d881862e4dd27c040",
            "3814d02d119042439dfc4659cf053541",
            "69608a32b7dd4fabb75a2e14ba9bcc39",
            "4ce17053ebf1410983b64a17dcc08c66",
            "80023eb93616449a88698f70fdf849fe",
            "9ca7cfd48c7340e9a4c0b82e86d5bc09",
            "913de7f5431f4ad0a19ade8f2d71cd2f",
            "fc67c69256c947a8aa65a6f3f707c285",
            "3cddcc7abb8c41979779546e7e771b9f",
            "e03887a658c84139b6739ab4e6bc1048"
          ]
        },
        "id": "668FMRBJXj9T",
        "outputId": "d838c876-9097-4075-db0e-f43a0b826954"
      },
      "outputs": [],
      "source": [
        "# Cell 16: Test Step 1 Output (Run after Cell 12)\n",
        "def test_step1_output():\n",
        "    \"\"\"Simple test to see Step 1 outputs\"\"\"\n",
        "    print(\"TESTING STEP 1 - BASIC RAG\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Upload PDF\n",
        "    pdf_filename = upload_pdf_file()\n",
        "\n",
        "    if pdf_filename:\n",
        "        # Initialize and setup Step 1\n",
        "        basic_rag = BasicRAGPipeline()\n",
        "        basic_rag.setup(pdf_filename)\n",
        "\n",
        "        # Test with sample queries\n",
        "        test_queries = [\n",
        "            \"What was Meta's revenue in Q1 2024?\",\n",
        "            \"What were the key financial highlights for Meta in Q1 2024?\"\n",
        "        ]\n",
        "\n",
        "        for i, query in enumerate(test_queries, 1):\n",
        "            print(f\"\\nTEST {i}:\")\n",
        "            print(f\"Query: {query}\")\n",
        "            result = basic_rag.query(query)\n",
        "            print(f\"Answer: {result['answer']}\")\n",
        "            print(f\"Retrieved chunks: {len(result['retrieved_chunks'])}\")\n",
        "            print(\"-\" * 30)\n",
        "\n",
        "        return basic_rag\n",
        "    else:\n",
        "        print(\"No PDF uploaded\")\n",
        "        return None\n",
        "\n",
        "# Run Step 1 test\n",
        "basic_rag = test_step1_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5N97zJuZFM7"
      },
      "outputs": [],
      "source": [
        "#step 3\n",
        "!pip install -q nltk rouge-score rank_bm25\n",
        "import nltk\n",
        "from rouge_score import rouge_scorer\n",
        "from rank_bm25 import BM25Okapi\n",
        "from collections import defaultdict, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4qQhTE7ZJK6"
      },
      "outputs": [],
      "source": [
        "class QueryOptimizer:\n",
        "    def __init__(self):\n",
        "        self.financial_synonyms = {\n",
        "            'revenue': ['sales', 'income', 'earnings', 'turnover'],\n",
        "            'profit': ['income', 'earnings', 'gains'],\n",
        "            'expenses': ['costs', 'expenditures', 'spending'],\n",
        "            'growth': ['increase', 'rise', 'expansion'],\n",
        "            'margin': ['profitability', 'profit margin'],\n",
        "            'quarter': ['Q1', 'Q2', 'Q3', 'Q4', 'quarterly']\n",
        "        }\n",
        "\n",
        "        self.temporal_patterns = {\n",
        "            'Q1 2024': ['first quarter 2024', 'Q1 24', 'quarter 1 2024'],\n",
        "            'Q1 2023': ['first quarter 2023', 'Q1 23', 'quarter 1 2023'],\n",
        "            'year-over-year': ['YoY', 'annual growth', 'yearly comparison']\n",
        "        }\n",
        "\n",
        "    def optimize_query(self, query):\n",
        "        \"\"\"Optimize and expand query for better retrieval\"\"\"\n",
        "        original_query = query\n",
        "\n",
        "        # Query expansion with synonyms\n",
        "        expanded_query = self._expand_with_synonyms(query)\n",
        "\n",
        "        # Query decomposition for complex queries\n",
        "        sub_queries = self._decompose_query(query)\n",
        "\n",
        "        # Query type classification\n",
        "        query_type = self._classify_query(query)\n",
        "\n",
        "        # Generate search variations\n",
        "        search_variations = self._generate_variations(expanded_query)\n",
        "\n",
        "        return {\n",
        "            'original': original_query,\n",
        "            'expanded': expanded_query,\n",
        "            'sub_queries': sub_queries,\n",
        "            'query_type': query_type,\n",
        "            'search_variations': search_variations,\n",
        "            'optimization_applied': True\n",
        "        }\n",
        "\n",
        "    def _expand_with_synonyms(self, query):\n",
        "        words = query.lower().split()\n",
        "        expanded_words = []\n",
        "\n",
        "        for word in words:\n",
        "            expanded_words.append(word)\n",
        "            for term, synonyms in self.financial_synonyms.items():\n",
        "                if term in word:\n",
        "                    expanded_words.extend(synonyms[:2])\n",
        "\n",
        "        return ' '.join(expanded_words)\n",
        "\n",
        "    def _decompose_query(self, query):\n",
        "        sub_queries = [query]\n",
        "\n",
        "        if any(word in query.lower() for word in ['compared to', 'vs', 'versus', 'difference']):\n",
        "            if '2024' in query and '2023' in query:\n",
        "                sub_queries.append(query.replace('compared to Q1 2023', '').replace('vs Q1 2023', ''))\n",
        "                sub_queries.append(query.replace('Q1 2024', 'Q1 2023'))\n",
        "\n",
        "        if 'summarize' in query.lower():\n",
        "            if 'expenses' in query.lower():\n",
        "                sub_queries.extend([\n",
        "                    'operating expenses breakdown',\n",
        "                    'cost of revenue',\n",
        "                    'research and development expenses'\n",
        "                ])\n",
        "\n",
        "        return list(set(sub_queries))\n",
        "\n",
        "    def _classify_query(self, query):\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        if any(word in query_lower for word in ['compared to', 'vs', 'versus', 'difference', 'change']):\n",
        "            return 'comparative'\n",
        "        elif any(word in query_lower for word in ['summarize', 'summary', 'overview', 'breakdown']):\n",
        "            return 'summary'\n",
        "        elif any(word in query_lower for word in ['revenue', 'income', 'expenses', 'margin', 'profit']):\n",
        "            return 'financial_metric'\n",
        "        elif '?' in query:\n",
        "            return 'factual'\n",
        "        else:\n",
        "            return 'general'\n",
        "\n",
        "    def _generate_variations(self, query):\n",
        "        variations = [query]\n",
        "\n",
        "        for pattern, alternatives in self.temporal_patterns.items():\n",
        "            if pattern.lower() in query.lower():\n",
        "                for alt in alternatives:\n",
        "                    variations.append(query.replace(pattern, alt))\n",
        "\n",
        "        if 'what was' in query.lower():\n",
        "            variations.append(query.replace('What was', 'Show me'))\n",
        "            variations.append(query.replace('What was', 'Find'))\n",
        "\n",
        "        return list(set(variations))[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjfLWP6_ZZqL"
      },
      "outputs": [],
      "source": [
        "class AdvancedRetriever:\n",
        "    def __init__(self, embedding_model_name='all-MiniLM-L6-v2'):\n",
        "        self.embedding_model = SentenceTransformer(embedding_model_name)\n",
        "        self.bm25 = None\n",
        "\n",
        "        # Storage for different retrieval methods\n",
        "        self.text_chunks = []\n",
        "        self.structured_data = {}\n",
        "        self.text_embeddings = None\n",
        "        self.text_index = None\n",
        "        self.table_embeddings = None\n",
        "        self.table_texts = []\n",
        "        self.table_index = None\n",
        "\n",
        "        # Advanced features\n",
        "        self.chunk_metadata = []\n",
        "        self.retrieval_history = []\n",
        "\n",
        "    def setup_advanced_retrieval(self, text_chunks, structured_data, chunk_sizes=[300, 500, 800]):\n",
        "        \"\"\"Setup advanced retrieval with multiple chunk sizes and re-ranking\"\"\"\n",
        "        print(f\"Setting up advanced retrieval system...\")\n",
        "\n",
        "        self.text_chunks = text_chunks\n",
        "        self.structured_data = structured_data\n",
        "\n",
        "        # Create multi-scale chunks\n",
        "        self.multi_scale_chunks = self._create_multi_scale_chunks(text_chunks, chunk_sizes)\n",
        "\n",
        "        # Setup embeddings for all chunk scales\n",
        "        all_chunks = []\n",
        "        chunk_metadata = []\n",
        "\n",
        "        for scale, chunks in self.multi_scale_chunks.items():\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                all_chunks.append(chunk)\n",
        "                chunk_metadata.append({\n",
        "                    'chunk_id': len(all_chunks) - 1,\n",
        "                    'scale': scale,\n",
        "                    'original_index': i,\n",
        "                    'length': len(chunk),\n",
        "                    'type': 'text'\n",
        "                })\n",
        "\n",
        "        # Add table texts\n",
        "        for table_id, table_info in structured_data.items():\n",
        "            table_text = table_info['text_representation']\n",
        "            all_chunks.append(table_text)\n",
        "            chunk_metadata.append({\n",
        "                'chunk_id': len(all_chunks) - 1,\n",
        "                'scale': 'table',\n",
        "                'table_id': table_id,\n",
        "                'length': len(table_text),\n",
        "                'type': 'structured'\n",
        "            })\n",
        "\n",
        "        self.all_chunks = all_chunks\n",
        "        self.chunk_metadata = chunk_metadata\n",
        "\n",
        "        # Create embeddings\n",
        "        print(\"Creating embeddings for advanced retrieval...\")\n",
        "        self.all_embeddings = self.embedding_model.encode(all_chunks, show_progress_bar=True)\n",
        "\n",
        "        # Create FAISS index\n",
        "        dimension = self.all_embeddings.shape[1]\n",
        "        self.advanced_index = faiss.IndexFlatIP(dimension)\n",
        "        faiss.normalize_L2(self.all_embeddings.astype('float32'))\n",
        "        self.advanced_index.add(self.all_embeddings.astype('float32'))\n",
        "\n",
        "        # Setup BM25 for keyword search\n",
        "        tokenized_chunks = [chunk.lower().split() for chunk in all_chunks]\n",
        "        self.bm25 = BM25Okapi(tokenized_chunks)\n",
        "\n",
        "        print(f\"Advanced retrieval setup complete:\")\n",
        "        print(f\"  Total chunks: {len(all_chunks)}\")\n",
        "        print(f\"  Multi-scale chunks: {len(self.multi_scale_chunks)}\")\n",
        "        print(f\"  BM25 index ready\")\n",
        "\n",
        "    def _create_multi_scale_chunks(self, text_chunks, chunk_sizes):\n",
        "        \"\"\"Create chunks of different sizes for multi-scale retrieval\"\"\"\n",
        "        full_text = ' '.join(text_chunks)\n",
        "        words = full_text.split()\n",
        "\n",
        "        multi_scale = {}\n",
        "\n",
        "        for size in chunk_sizes:\n",
        "            chunks = []\n",
        "            overlap = size // 10\n",
        "\n",
        "            for i in range(0, len(words), size - overlap):\n",
        "                chunk = ' '.join(words[i:i + size])\n",
        "                if len(chunk.strip()) > 50:\n",
        "                    chunks.append(chunk.strip())\n",
        "\n",
        "            multi_scale[f'scale_{size}'] = chunks\n",
        "\n",
        "        return multi_scale\n",
        "\n",
        "    def advanced_search(self, optimized_query, top_k=10):\n",
        "        \"\"\"Advanced search with multiple methods and re-ranking\"\"\"\n",
        "        all_results = []\n",
        "\n",
        "        # Search with original and expanded queries\n",
        "        queries_to_search = [\n",
        "            optimized_query['original'],\n",
        "            optimized_query['expanded']\n",
        "        ] + optimized_query['sub_queries']\n",
        "\n",
        "        for query in queries_to_search[:5]:\n",
        "            # Vector search\n",
        "            vector_results = self._vector_search(query, top_k//2)\n",
        "            # BM25 search\n",
        "            bm25_results = self._bm25_search(query, top_k//2)\n",
        "\n",
        "            all_results.extend(vector_results)\n",
        "            all_results.extend(bm25_results)\n",
        "\n",
        "        # Remove duplicates and initial ranking\n",
        "        unique_results = self._deduplicate_results(all_results)\n",
        "\n",
        "        # Simple re-ranking based on score\n",
        "        reranked_results = sorted(unique_results, key=lambda x: x.get('score', 0), reverse=True)\n",
        "\n",
        "        # Final filtering and metadata addition\n",
        "        final_results = self._add_metadata_and_filter(reranked_results[:top_k])\n",
        "\n",
        "        # Store retrieval history\n",
        "        self.retrieval_history.append({\n",
        "            'query': optimized_query['original'],\n",
        "            'num_results': len(final_results),\n",
        "            'timestamp': time.time()\n",
        "        })\n",
        "\n",
        "        return final_results\n",
        "\n",
        "    def _vector_search(self, query, top_k):\n",
        "        \"\"\"Vector similarity search\"\"\"\n",
        "        query_embedding = self.embedding_model.encode([query])\n",
        "        faiss.normalize_L2(query_embedding.astype('float32'))\n",
        "\n",
        "        scores, indices = self.advanced_index.search(query_embedding.astype('float32'), top_k)\n",
        "\n",
        "        results = []\n",
        "        for score, idx in zip(scores[0], indices[0]):\n",
        "            if idx < len(self.all_chunks):\n",
        "                results.append({\n",
        "                    'content': self.all_chunks[idx],\n",
        "                    'score': float(score),\n",
        "                    'method': 'vector',\n",
        "                    'chunk_id': idx,\n",
        "                    'metadata': self.chunk_metadata[idx]\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _bm25_search(self, query, top_k):\n",
        "        \"\"\"BM25 keyword search\"\"\"\n",
        "        if not self.bm25:\n",
        "            return []\n",
        "\n",
        "        query_tokens = query.lower().split()\n",
        "        scores = self.bm25.get_scores(query_tokens)\n",
        "\n",
        "        top_indices = np.argsort(scores)[-top_k:][::-1]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            if scores[idx] > 0 and idx < len(self.all_chunks):\n",
        "                results.append({\n",
        "                    'content': self.all_chunks[idx],\n",
        "                    'score': float(scores[idx]),\n",
        "                    'method': 'bm25',\n",
        "                    'chunk_id': idx,\n",
        "                    'metadata': self.chunk_metadata[idx]\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _deduplicate_results(self, results):\n",
        "        \"\"\"Remove duplicate results\"\"\"\n",
        "        seen_content = set()\n",
        "        unique_results = []\n",
        "\n",
        "        for result in results:\n",
        "            content_key = result['content'][:100]\n",
        "            if content_key not in seen_content:\n",
        "                seen_content.add(content_key)\n",
        "                unique_results.append(result)\n",
        "\n",
        "        return unique_results\n",
        "\n",
        "    def _add_metadata_and_filter(self, results):\n",
        "        \"\"\"Add metadata and apply final filtering\"\"\"\n",
        "        enhanced_results = []\n",
        "\n",
        "        for result in results:\n",
        "            metadata = result['metadata']\n",
        "\n",
        "            enhanced_result = {\n",
        "                **result,\n",
        "                'type': metadata['type'],\n",
        "                'chunk_scale': metadata.get('scale', 'unknown'),\n",
        "                'relevance_score': result.get('score', 0)\n",
        "            }\n",
        "\n",
        "            # Add structured data if available\n",
        "            if metadata['type'] == 'structured':\n",
        "                table_id = metadata.get('table_id')\n",
        "                if table_id in self.structured_data:\n",
        "                    enhanced_result['structured_info'] = self.structured_data[table_id]\n",
        "\n",
        "            enhanced_results.append(enhanced_result)\n",
        "\n",
        "        return enhanced_results\n",
        "\n",
        "    def iterative_retrieval(self, optimized_query, max_iterations=3):\n",
        "        \"\"\"Iterative retrieval for complex queries\"\"\"\n",
        "        all_results = []\n",
        "        current_query = optimized_query['original']\n",
        "\n",
        "        for iteration in range(max_iterations):\n",
        "            print(f\"Iterative retrieval - iteration {iteration + 1}\")\n",
        "\n",
        "            results = self.advanced_search(optimized_query, top_k=5)\n",
        "            all_results.extend(results)\n",
        "\n",
        "            if len(set(r['content'][:50] for r in all_results)) >= 10:\n",
        "                break\n",
        "\n",
        "            if iteration < max_iterations - 1:\n",
        "                if iteration < len(optimized_query['sub_queries']):\n",
        "                    optimized_query['original'] = optimized_query['sub_queries'][iteration]\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "        final_results = self._deduplicate_results(all_results)\n",
        "        return final_results[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrUYqbH_ZeAF"
      },
      "outputs": [],
      "source": [
        "# Cell 27: Additional imports for Step 3\n",
        "!pip install -q nltk rouge-score rank_bm25\n",
        "\n",
        "import nltk\n",
        "from rouge_score import rouge_scorer\n",
        "from rank_bm25 import BM25Okapi\n",
        "from collections import defaultdict, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download NLTK data\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Cell 28: Query Optimizer\n",
        "class QueryOptimizer:\n",
        "    def __init__(self):\n",
        "        self.financial_synonyms = {\n",
        "            'revenue': ['sales', 'income', 'earnings', 'turnover'],\n",
        "            'profit': ['income', 'earnings', 'gains'],\n",
        "            'expenses': ['costs', 'expenditures', 'spending'],\n",
        "            'growth': ['increase', 'rise', 'expansion'],\n",
        "            'margin': ['profitability', 'profit margin'],\n",
        "            'quarter': ['Q1', 'Q2', 'Q3', 'Q4', 'quarterly']\n",
        "        }\n",
        "\n",
        "        self.temporal_patterns = {\n",
        "            'Q1 2024': ['first quarter 2024', 'Q1 24', 'quarter 1 2024'],\n",
        "            'Q1 2023': ['first quarter 2023', 'Q1 23', 'quarter 1 2023'],\n",
        "            'year-over-year': ['YoY', 'annual growth', 'yearly comparison']\n",
        "        }\n",
        "\n",
        "    def optimize_query(self, query):\n",
        "        \"\"\"Optimize and expand query for better retrieval\"\"\"\n",
        "        original_query = query\n",
        "\n",
        "        # Query expansion with synonyms\n",
        "        expanded_query = self._expand_with_synonyms(query)\n",
        "\n",
        "        # Query decomposition for complex queries\n",
        "        sub_queries = self._decompose_query(query)\n",
        "\n",
        "        # Query type classification\n",
        "        query_type = self._classify_query(query)\n",
        "\n",
        "        # Generate search variations\n",
        "        search_variations = self._generate_variations(expanded_query)\n",
        "\n",
        "        return {\n",
        "            'original': original_query,\n",
        "            'expanded': expanded_query,\n",
        "            'sub_queries': sub_queries,\n",
        "            'query_type': query_type,\n",
        "            'search_variations': search_variations,\n",
        "            'optimization_applied': True\n",
        "        }\n",
        "\n",
        "    def _expand_with_synonyms(self, query):\n",
        "        words = query.lower().split()\n",
        "        expanded_words = []\n",
        "\n",
        "        for word in words:\n",
        "            expanded_words.append(word)\n",
        "            for term, synonyms in self.financial_synonyms.items():\n",
        "                if term in word:\n",
        "                    expanded_words.extend(synonyms[:2])\n",
        "\n",
        "        return ' '.join(expanded_words)\n",
        "\n",
        "    def _decompose_query(self, query):\n",
        "        sub_queries = [query]\n",
        "\n",
        "        if any(word in query.lower() for word in ['compared to', 'vs', 'versus', 'difference']):\n",
        "            if '2024' in query and '2023' in query:\n",
        "                sub_queries.append(query.replace('compared to Q1 2023', '').replace('vs Q1 2023', ''))\n",
        "                sub_queries.append(query.replace('Q1 2024', 'Q1 2023'))\n",
        "\n",
        "        if 'summarize' in query.lower():\n",
        "            if 'expenses' in query.lower():\n",
        "                sub_queries.extend([\n",
        "                    'operating expenses breakdown',\n",
        "                    'cost of revenue',\n",
        "                    'research and development expenses'\n",
        "                ])\n",
        "\n",
        "        return list(set(sub_queries))\n",
        "\n",
        "    def _classify_query(self, query):\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        if any(word in query_lower for word in ['compared to', 'vs', 'versus', 'difference', 'change']):\n",
        "            return 'comparative'\n",
        "        elif any(word in query_lower for word in ['summarize', 'summary', 'overview', 'breakdown']):\n",
        "            return 'summary'\n",
        "        elif any(word in query_lower for word in ['revenue', 'income', 'expenses', 'margin', 'profit']):\n",
        "            return 'financial_metric'\n",
        "        elif '?' in query:\n",
        "            return 'factual'\n",
        "        else:\n",
        "            return 'general'\n",
        "\n",
        "    def _generate_variations(self, query):\n",
        "        variations = [query]\n",
        "\n",
        "        for pattern, alternatives in self.temporal_patterns.items():\n",
        "            if pattern.lower() in query.lower():\n",
        "                for alt in alternatives:\n",
        "                    variations.append(query.replace(pattern, alt))\n",
        "\n",
        "        if 'what was' in query.lower():\n",
        "            variations.append(query.replace('What was', 'Show me'))\n",
        "            variations.append(query.replace('What was', 'Find'))\n",
        "\n",
        "        return list(set(variations))[:5]\n",
        "\n",
        "# Cell 29: Advanced Retriever with Re-ranking\n",
        "class AdvancedRetriever:\n",
        "    def __init__(self, embedding_model_name='all-MiniLM-L6-v2'):\n",
        "        self.embedding_model = SentenceTransformer(embedding_model_name)\n",
        "        self.bm25 = None\n",
        "\n",
        "        # Storage for different retrieval methods\n",
        "        self.text_chunks = []\n",
        "        self.structured_data = {}\n",
        "        self.text_embeddings = None\n",
        "        self.text_index = None\n",
        "        self.table_embeddings = None\n",
        "        self.table_texts = []\n",
        "        self.table_index = None\n",
        "\n",
        "        # Advanced features\n",
        "        self.chunk_metadata = []\n",
        "        self.retrieval_history = []\n",
        "\n",
        "    def setup_advanced_retrieval(self, text_chunks, structured_data, chunk_sizes=[300, 500, 800]):\n",
        "        \"\"\"Setup advanced retrieval with multiple chunk sizes and re-ranking\"\"\"\n",
        "        print(f\"Setting up advanced retrieval system...\")\n",
        "\n",
        "        self.text_chunks = text_chunks\n",
        "        self.structured_data = structured_data\n",
        "\n",
        "        # Create multi-scale chunks\n",
        "        self.multi_scale_chunks = self._create_multi_scale_chunks(text_chunks, chunk_sizes)\n",
        "\n",
        "        # Setup embeddings for all chunk scales\n",
        "        all_chunks = []\n",
        "        chunk_metadata = []\n",
        "\n",
        "        for scale, chunks in self.multi_scale_chunks.items():\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                all_chunks.append(chunk)\n",
        "                chunk_metadata.append({\n",
        "                    'chunk_id': len(all_chunks) - 1,\n",
        "                    'scale': scale,\n",
        "                    'original_index': i,\n",
        "                    'length': len(chunk),\n",
        "                    'type': 'text'\n",
        "                })\n",
        "\n",
        "        # Add table texts\n",
        "        for table_id, table_info in structured_data.items():\n",
        "            table_text = table_info['text_representation']\n",
        "            all_chunks.append(table_text)\n",
        "            chunk_metadata.append({\n",
        "                'chunk_id': len(all_chunks) - 1,\n",
        "                'scale': 'table',\n",
        "                'table_id': table_id,\n",
        "                'length': len(table_text),\n",
        "                'type': 'structured'\n",
        "            })\n",
        "\n",
        "        self.all_chunks = all_chunks\n",
        "        self.chunk_metadata = chunk_metadata\n",
        "\n",
        "        # Create embeddings\n",
        "        print(\"Creating embeddings for advanced retrieval...\")\n",
        "        self.all_embeddings = self.embedding_model.encode(all_chunks, show_progress_bar=True)\n",
        "\n",
        "        # Create FAISS index\n",
        "        dimension = self.all_embeddings.shape[1]\n",
        "        self.advanced_index = faiss.IndexFlatIP(dimension)\n",
        "        faiss.normalize_L2(self.all_embeddings.astype('float32'))\n",
        "        self.advanced_index.add(self.all_embeddings.astype('float32'))\n",
        "\n",
        "        # Setup BM25 for keyword search\n",
        "        tokenized_chunks = [chunk.lower().split() for chunk in all_chunks]\n",
        "        self.bm25 = BM25Okapi(tokenized_chunks)\n",
        "\n",
        "        print(f\"Advanced retrieval setup complete:\")\n",
        "        print(f\"  Total chunks: {len(all_chunks)}\")\n",
        "        print(f\"  Multi-scale chunks: {len(self.multi_scale_chunks)}\")\n",
        "        print(f\"  BM25 index ready\")\n",
        "\n",
        "    def _create_multi_scale_chunks(self, text_chunks, chunk_sizes):\n",
        "        \"\"\"Create chunks of different sizes for multi-scale retrieval\"\"\"\n",
        "        full_text = ' '.join(text_chunks)\n",
        "        words = full_text.split()\n",
        "\n",
        "        multi_scale = {}\n",
        "\n",
        "        for size in chunk_sizes:\n",
        "            chunks = []\n",
        "            overlap = size // 10\n",
        "\n",
        "            for i in range(0, len(words), size - overlap):\n",
        "                chunk = ' '.join(words[i:i + size])\n",
        "                if len(chunk.strip()) > 50:\n",
        "                    chunks.append(chunk.strip())\n",
        "\n",
        "            multi_scale[f'scale_{size}'] = chunks\n",
        "\n",
        "        return multi_scale\n",
        "\n",
        "    def advanced_search(self, optimized_query, top_k=10):\n",
        "        \"\"\"Advanced search with multiple methods and re-ranking\"\"\"\n",
        "        all_results = []\n",
        "\n",
        "        # Search with original and expanded queries\n",
        "        queries_to_search = [\n",
        "            optimized_query['original'],\n",
        "            optimized_query['expanded']\n",
        "        ] + optimized_query['sub_queries']\n",
        "\n",
        "        for query in queries_to_search[:5]:\n",
        "            # Vector search\n",
        "            vector_results = self._vector_search(query, top_k//2)\n",
        "            # BM25 search\n",
        "            bm25_results = self._bm25_search(query, top_k//2)\n",
        "\n",
        "            all_results.extend(vector_results)\n",
        "            all_results.extend(bm25_results)\n",
        "\n",
        "        # Remove duplicates and initial ranking\n",
        "        unique_results = self._deduplicate_results(all_results)\n",
        "\n",
        "        # Simple re-ranking based on score\n",
        "        reranked_results = sorted(unique_results, key=lambda x: x.get('score', 0), reverse=True)\n",
        "\n",
        "        # Final filtering and metadata addition\n",
        "        final_results = self._add_metadata_and_filter(reranked_results[:top_k])\n",
        "\n",
        "        # Store retrieval history\n",
        "        self.retrieval_history.append({\n",
        "            'query': optimized_query['original'],\n",
        "            'num_results': len(final_results),\n",
        "            'timestamp': time.time()\n",
        "        })\n",
        "\n",
        "        return final_results\n",
        "\n",
        "    def _vector_search(self, query, top_k):\n",
        "        \"\"\"Vector similarity search\"\"\"\n",
        "        query_embedding = self.embedding_model.encode([query])\n",
        "        faiss.normalize_L2(query_embedding.astype('float32'))\n",
        "\n",
        "        scores, indices = self.advanced_index.search(query_embedding.astype('float32'), top_k)\n",
        "\n",
        "        results = []\n",
        "        for score, idx in zip(scores[0], indices[0]):\n",
        "            if idx < len(self.all_chunks):\n",
        "                results.append({\n",
        "                    'content': self.all_chunks[idx],\n",
        "                    'score': float(score),\n",
        "                    'method': 'vector',\n",
        "                    'chunk_id': idx,\n",
        "                    'metadata': self.chunk_metadata[idx]\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _bm25_search(self, query, top_k):\n",
        "        \"\"\"BM25 keyword search\"\"\"\n",
        "        if not self.bm25:\n",
        "            return []\n",
        "\n",
        "        query_tokens = query.lower().split()\n",
        "        scores = self.bm25.get_scores(query_tokens)\n",
        "\n",
        "        top_indices = np.argsort(scores)[-top_k:][::-1]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            if scores[idx] > 0 and idx < len(self.all_chunks):\n",
        "                results.append({\n",
        "                    'content': self.all_chunks[idx],\n",
        "                    'score': float(scores[idx]),\n",
        "                    'method': 'bm25',\n",
        "                    'chunk_id': idx,\n",
        "                    'metadata': self.chunk_metadata[idx]\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _deduplicate_results(self, results):\n",
        "        \"\"\"Remove duplicate results\"\"\"\n",
        "        seen_content = set()\n",
        "        unique_results = []\n",
        "\n",
        "        for result in results:\n",
        "            content_key = result['content'][:100]\n",
        "            if content_key not in seen_content:\n",
        "                seen_content.add(content_key)\n",
        "                unique_results.append(result)\n",
        "\n",
        "        return unique_results\n",
        "\n",
        "    def _add_metadata_and_filter(self, results):\n",
        "        \"\"\"Add metadata and apply final filtering\"\"\"\n",
        "        enhanced_results = []\n",
        "\n",
        "        for result in results:\n",
        "            metadata = result['metadata']\n",
        "\n",
        "            enhanced_result = {\n",
        "                **result,\n",
        "                'type': metadata['type'],\n",
        "                'chunk_scale': metadata.get('scale', 'unknown'),\n",
        "                'relevance_score': result.get('score', 0)\n",
        "            }\n",
        "\n",
        "            # Add structured data if available\n",
        "            if metadata['type'] == 'structured':\n",
        "                table_id = metadata.get('table_id')\n",
        "                if table_id in self.structured_data:\n",
        "                    enhanced_result['structured_info'] = self.structured_data[table_id]\n",
        "\n",
        "            enhanced_results.append(enhanced_result)\n",
        "\n",
        "        return enhanced_results\n",
        "\n",
        "    def iterative_retrieval(self, optimized_query, max_iterations=3):\n",
        "        \"\"\"Iterative retrieval for complex queries\"\"\"\n",
        "        all_results = []\n",
        "        current_query = optimized_query['original']\n",
        "\n",
        "        for iteration in range(max_iterations):\n",
        "            print(f\"Iterative retrieval - iteration {iteration + 1}\")\n",
        "\n",
        "            results = self.advanced_search(optimized_query, top_k=5)\n",
        "            all_results.extend(results)\n",
        "\n",
        "            if len(set(r['content'][:50] for r in all_results)) >= 10:\n",
        "                break\n",
        "\n",
        "            if iteration < max_iterations - 1:\n",
        "                if iteration < len(optimized_query['sub_queries']):\n",
        "                    optimized_query['original'] = optimized_query['sub_queries'][iteration]\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "        final_results = self._deduplicate_results(all_results)\n",
        "        return final_results[:10]\n",
        "\n",
        "# Cell 30: Advanced Answer Generator\n",
        "class AdvancedGenerator:\n",
        "    def __init__(self):\n",
        "        self.answer_templates = {\n",
        "            'comparative': self._generate_comparative_answer,\n",
        "            'summary': self._generate_summary_answer,\n",
        "            'financial_metric': self._generate_financial_answer,\n",
        "            'factual': self._generate_factual_answer,\n",
        "            'general': self._generate_general_answer\n",
        "        }\n",
        "\n",
        "    def generate_enhanced_answer(self, optimized_query, search_results, max_length=300):\n",
        "        \"\"\"Generate enhanced answer using query type and multiple sources\"\"\"\n",
        "        query_type = optimized_query['query_type']\n",
        "        original_query = optimized_query['original']\n",
        "\n",
        "        # Use appropriate template\n",
        "        generator_func = self.answer_templates.get(query_type, self._generate_general_answer)\n",
        "\n",
        "        # Generate answer with context\n",
        "        answer = generator_func(original_query, search_results, max_length)\n",
        "\n",
        "        # Post-process answer\n",
        "        answer = self._post_process_answer(answer, search_results)\n",
        "\n",
        "        return answer\n",
        "\n",
        "    def _generate_comparative_answer(self, query, results, max_length):\n",
        "        \"\"\"Generate comparative answer with specific metrics\"\"\"\n",
        "        if 'net income' in query.lower():\n",
        "            all_content = \"\"\n",
        "            for result in results:\n",
        "                all_content += result['content'] + \" \"\n",
        "\n",
        "            # Look for specific net income figures\n",
        "            income_2024_match = re.search(r'(?:net income|income).*?(?:2024).*?\\$?\\s*(12[,.]?369|12369)', all_content, re.IGNORECASE)\n",
        "            income_2023_match = re.search(r'(?:net income|income).*?(?:2023).*?\\$?\\s*(5[,.]?709|5709)', all_content, re.IGNORECASE)\n",
        "\n",
        "            # Alternative patterns\n",
        "            if not income_2024_match:\n",
        "                income_2024_match = re.search(r'12[,.]?369.*?(?:million|billion)', all_content, re.IGNORECASE)\n",
        "            if not income_2023_match:\n",
        "                income_2023_match = re.search(r'5[,.]?709.*?(?:million|billion)', all_content, re.IGNORECASE)\n",
        "\n",
        "            if income_2024_match and income_2023_match:\n",
        "                income_2024 = income_2024_match.group(1).replace(',', '') if income_2024_match.lastindex else income_2024_match.group(0).replace(',', '').replace('million', '').replace('billion', '').strip()\n",
        "                income_2023 = income_2023_match.group(1).replace(',', '') if income_2023_match.lastindex else income_2023_match.group(0).replace(',', '').replace('million', '').replace('billion', '').strip()\n",
        "\n",
        "                # Extract just the numbers\n",
        "                income_2024_num = re.search(r'(12\\.?369|12369)', income_2024)\n",
        "                income_2023_num = re.search(r'(5\\.?709|5709)', income_2023)\n",
        "\n",
        "                if income_2024_num and income_2023_num:\n",
        "                    val_2024 = income_2024_num.group(1)\n",
        "                    val_2023 = income_2023_num.group(1)\n",
        "\n",
        "                    try:\n",
        "                        change_pct = ((float(val_2024.replace('.', '')) - float(val_2023.replace('.', ''))) / float(val_2023.replace('.', ''))) * 100\n",
        "                        return f\"Meta's net income was ${val_2024} billion in Q1 2024 compared to ${val_2023} billion in Q1 2023, representing a {change_pct:.0f}% increase year-over-year.\"\n",
        "                    except:\n",
        "                        return f\"Meta's net income was ${val_2024} billion in Q1 2024 compared to ${val_2023} billion in Q1 2023.\"\n",
        "\n",
        "        # Fallback\n",
        "        return \"Based on the financial data: \" + results[0]['content'][:150] + \"...\" if results else \"No comparison data available.\"\n",
        "\n",
        "    def _generate_summary_answer(self, query, results, max_length):\n",
        "        \"\"\"Generate summary answer aggregating multiple sources\"\"\"\n",
        "        if 'expenses' in query.lower() or 'operating expenses' in query.lower():\n",
        "            all_content = \"\"\n",
        "            for result in results:\n",
        "                all_content += result['content'] + \" \"\n",
        "\n",
        "            # Look for expense breakdown\n",
        "            expense_patterns = {\n",
        "                'Cost of revenue': r'(?:cost of revenue|Cost of revenue).*?\\$?\\s*(6[,.]?640|6640)',\n",
        "                'Research and development': r'(?:research and development|R&D).*?\\$?\\s*(9[,.]?978|9978)',\n",
        "                'Marketing and sales': r'(?:marketing and sales|Marketing).*?\\$?\\s*(2[,.]?564|2564)',\n",
        "                'General and administrative': r'(?:general and administrative|G&A).*?\\$?\\s*(3[,.]?455|3455)'\n",
        "            }\n",
        "\n",
        "            expenses_found = {}\n",
        "            for category, pattern in expense_patterns.items():\n",
        "                match = re.search(pattern, all_content, re.IGNORECASE)\n",
        "                if match:\n",
        "                    amount = match.group(1).replace(',', '')\n",
        "                    # Convert to billions\n",
        "                    if '.' not in amount and len(amount) == 4:\n",
        "                        amount = amount[:1] + '.' + amount[1:]\n",
        "                    expenses_found[category] = amount\n",
        "\n",
        "            if expenses_found:\n",
        "                expense_list = [f\"{cat}: ${amt} billion\" for cat, amt in expenses_found.items()]\n",
        "                total_match = re.search(r'(?:total costs|total expenses).*?\\$?\\s*(22[,.]?637|22637)', all_content, re.IGNORECASE)\n",
        "\n",
        "                result = f\"Meta's Q1 2024 operating expenses breakdown: {'; '.join(expense_list)}\"\n",
        "                if total_match:\n",
        "                    total = total_match.group(1).replace(',', '')\n",
        "                    if '.' not in total:\n",
        "                        total = total[:2] + '.' + total[2:]\n",
        "                    result += f\". Total costs and expenses: ${total} billion\"\n",
        "\n",
        "                return result + \".\"\n",
        "\n",
        "        return \"Summary based on available data: \" + results[0]['content'][:200] + \"...\" if results else \"No summary data available.\"\n",
        "\n",
        "    def _generate_financial_answer(self, query, results, max_length):\n",
        "        return self._generate_general_answer(query, results, max_length)\n",
        "\n",
        "    def _generate_factual_answer(self, query, results, max_length):\n",
        "        structured_results = [r for r in results if r.get('type') == 'structured']\n",
        "        text_results = [r for r in results if r.get('type') == 'text']\n",
        "\n",
        "        if structured_results and 'structured_info' in structured_results[0]:\n",
        "            kv_pairs = structured_results[0]['structured_info'].get('key_value_pairs', {})\n",
        "            if kv_pairs:\n",
        "                query_words = set(query.lower().split())\n",
        "                best_match = None\n",
        "                best_score = 0\n",
        "\n",
        "                for key, value in kv_pairs.items():\n",
        "                    key_words = set(key.lower().split())\n",
        "                    overlap = len(query_words.intersection(key_words))\n",
        "                    if overlap > best_score:\n",
        "                        best_score = overlap\n",
        "                        best_match = (key, value)\n",
        "\n",
        "                if best_match:\n",
        "                    return f\"According to the financial report: {best_match[0]}: {best_match[1]}\"\n",
        "\n",
        "        if text_results:\n",
        "            return f\"Based on the report: {text_results[0]['content'][:200]}...\"\n",
        "\n",
        "        return \"I found relevant information in the financial report, but couldn't extract a specific answer.\"\n",
        "\n",
        "    def _generate_general_answer(self, query, results, max_length):\n",
        "        if not results:\n",
        "            return \"I couldn't find relevant information to answer your question.\"\n",
        "\n",
        "        text_parts = []\n",
        "        structured_parts = []\n",
        "\n",
        "        for result in results[:3]:\n",
        "            if result.get('type') == 'text':\n",
        "                text_parts.append(result['content'][:100])\n",
        "            elif result.get('type') == 'structured':\n",
        "                structured_parts.append(result['content'][:100])\n",
        "\n",
        "        answer_parts = []\n",
        "        if structured_parts:\n",
        "            answer_parts.append(f\"From structured data: {structured_parts[0]}...\")\n",
        "        if text_parts:\n",
        "            answer_parts.append(f\"Additional context: {text_parts[0]}...\")\n",
        "\n",
        "        return \" \".join(answer_parts)\n",
        "\n",
        "    def _post_process_answer(self, answer, results):\n",
        "        \"\"\"Post-process answer for clarity and consistency\"\"\"\n",
        "        answer = re.sub(r'\\s+', ' ', answer)\n",
        "        answer = re.sub(r'\\$\\s+(\\d)', r'$\\1', answer)\n",
        "\n",
        "        if answer and not answer.endswith('.'):\n",
        "            answer += '.'\n",
        "\n",
        "        num_sources = len(set(r['content'][:50] for r in results))\n",
        "        if num_sources > 1:\n",
        "            answer += f\" (Based on {num_sources} sources from the financial report)\"\n",
        "\n",
        "        return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWGaRa2-Zif6"
      },
      "outputs": [],
      "source": [
        "class AdvancedRAGPipeline:\n",
        "    def __init__(self):\n",
        "        self.pdf_processor = EnhancedPDFProcessor()\n",
        "        self.query_optimizer = QueryOptimizer()\n",
        "        self.advanced_retriever = AdvancedRetriever()\n",
        "        self.advanced_generator = AdvancedGenerator()\n",
        "\n",
        "        self.text_chunks = []\n",
        "        self.structured_data = {}\n",
        "        self.setup_complete = False\n",
        "\n",
        "        self.query_history = []\n",
        "        self.performance_metrics = defaultdict(list)\n",
        "\n",
        "    def setup(self, pdf_path, chunk_sizes=[300, 500, 800]):\n",
        "        \"\"\"Setup advanced RAG pipeline with query optimization and re-ranking\"\"\"\n",
        "        print(\"Setting up Advanced RAG Pipeline\")\n",
        "\n",
        "        # Extract text and tables\n",
        "        raw_text, tables = self.pdf_processor.extract_text_and_tables(pdf_path)\n",
        "\n",
        "        # Process text chunks\n",
        "        clean_text = self._clean_text(raw_text)\n",
        "        self.text_chunks = self._chunk_text(clean_text, 500, 50)\n",
        "\n",
        "        # Process structured data\n",
        "        self.structured_data = self.pdf_processor.process_structured_data(tables)\n",
        "\n",
        "        # Setup advanced retrieval\n",
        "        self.advanced_retriever.setup_advanced_retrieval(\n",
        "            self.text_chunks,\n",
        "            self.structured_data,\n",
        "            chunk_sizes\n",
        "        )\n",
        "\n",
        "        self.setup_complete = True\n",
        "\n",
        "        print(f\"Advanced RAG Pipeline setup complete!\")\n",
        "        print(f\"   - Text chunks: {len(self.text_chunks)}\")\n",
        "        print(f\"   - Tables: {len(self.structured_data)}\")\n",
        "        print(f\"   - Multi-scale chunks: {len(chunk_sizes)} scales\")\n",
        "        print(f\"   - Query optimization: Enabled\")\n",
        "        print(f\"   - Advanced retrieval: Ready\")\n",
        "\n",
        "    def query(self, question, use_iterative=False):\n",
        "        \"\"\"Advanced query processing with optimization and re-ranking\"\"\"\n",
        "        if not self.setup_complete:\n",
        "            raise ValueError(\"Pipeline not setup. Call setup() first.\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        print(f\"Advanced Query: {question}\")\n",
        "\n",
        "        # Query optimization\n",
        "        optimized_query = self.query_optimizer.optimize_query(question)\n",
        "        print(f\"Query type: {optimized_query['query_type']}\")\n",
        "        print(f\"Sub-queries: {len(optimized_query['sub_queries'])}\")\n",
        "\n",
        "        # Advanced retrieval\n",
        "        if use_iterative and optimized_query['query_type'] in ['comparative', 'summary']:\n",
        "            search_results = self.advanced_retriever.iterative_retrieval(optimized_query)\n",
        "            print(f\"Used iterative retrieval\")\n",
        "        else:\n",
        "            search_results = self.advanced_retriever.advanced_search(optimized_query)\n",
        "\n",
        "        print(f\"Retrieved {len(search_results)} results with advanced methods\")\n",
        "\n",
        "        # Display top results\n",
        "        for i, result in enumerate(search_results[:3]):\n",
        "            score = result.get('relevance_score', result.get('score', 0))\n",
        "            result_type = result.get('type', 'unknown')\n",
        "            content_preview = result['content'][:80] + \"...\" if len(result['content']) > 80 else result['content']\n",
        "            print(f\"   {i+1}. [{result_type.upper()}] Score: {score:.3f} - {content_preview}\")\n",
        "\n",
        "        # Enhanced answer generation\n",
        "        answer = self.advanced_generator.generate_enhanced_answer(optimized_query, search_results)\n",
        "\n",
        "        query_time = time.time() - start_time\n",
        "\n",
        "        print(f\"Enhanced Answer: {answer}\")\n",
        "        print(f\"Total time: {query_time:.3f}s\")\n",
        "\n",
        "        # Store performance metrics\n",
        "        self.performance_metrics['query_time'].append(query_time)\n",
        "        self.performance_metrics['num_results'].append(len(search_results))\n",
        "\n",
        "        # Store query history\n",
        "        query_record = {\n",
        "            'timestamp': time.time(),\n",
        "            'original_query': question,\n",
        "            'optimized_query': optimized_query,\n",
        "            'answer': answer,\n",
        "            'num_results': len(search_results),\n",
        "            'query_time': query_time,\n",
        "            'used_iterative': use_iterative\n",
        "        }\n",
        "        self.query_history.append(query_record)\n",
        "\n",
        "        return {\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'optimized_query': optimized_query,\n",
        "            'search_results': search_results,\n",
        "            'query_time': query_time,\n",
        "            'performance_metrics': {\n",
        "                'num_text_results': len([r for r in search_results if r.get('type') == 'text']),\n",
        "                'num_structured_results': len([r for r in search_results if r.get('type') == 'structured']),\n",
        "                'avg_relevance_score': sum(r.get('relevance_score', 0) for r in search_results) / len(search_results) if search_results else 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _clean_text(self, text):\n",
        "        text = re.sub(r'\\n+', '\\n', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'[^\\w\\s\\$\\%\\.\\,\\-\\(\\)]', ' ', text)\n",
        "        text = text.replace('$', '$ ')\n",
        "        text = text.replace('%', ' %')\n",
        "        return text.strip()\n",
        "\n",
        "    def _chunk_text(self, text, chunk_size, overlap):\n",
        "        words = text.split()\n",
        "        chunks = []\n",
        "\n",
        "        for i in range(0, len(words), chunk_size - overlap):\n",
        "            chunk = ' '.join(words[i:i + chunk_size])\n",
        "            if len(chunk.strip()) > 0:\n",
        "                chunks.append(chunk.strip())\n",
        "\n",
        "        return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "66b2d5c1be7c40c48753280cc51a9fd7",
            "572341ed0cc04639947825b76d2c5f16",
            "d76a57f54a2a4028ae821e58170138cc",
            "8b32ff7eabfc43319f47c1390b95de57",
            "342262d7df8643989fa2bdbed1b62a38",
            "845260479ad945d095f4ce148128b645",
            "1577824fba1c4b1c851d042d50c73e3d",
            "3ea9e640b9514eeea8fab0ff7629c8a7",
            "5a89259174b14fa1b32bed39d36e09a9",
            "96a2426cdb3146b68e2fb8253a609fef",
            "a8ebfece644e49b1ac2761720e20e5ad"
          ]
        },
        "id": "3U9hSI8VZjgT",
        "outputId": "36e51407-c4f1-4218-fc10-4be402b066b9"
      },
      "outputs": [],
      "source": [
        "def test_step3():\n",
        "    \"\"\"Test Step 3 Advanced RAG Pipeline\"\"\"\n",
        "    print(\"TESTING STEP 3 - ADVANCED RAG PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Upload PDF or use existing\n",
        "    pdf_filename = upload_pdf_file()\n",
        "\n",
        "    if pdf_filename:\n",
        "        # Initialize advanced pipeline\n",
        "        advanced_rag = AdvancedRAGPipeline()\n",
        "        advanced_rag.setup(pdf_filename)\n",
        "\n",
        "        # Test queries\n",
        "        test_queries = [\n",
        "            \"What was Meta's net income in Q1 2024 compared to Q1 2023?\",\n",
        "            \"Summarize Meta's operating expenses in Q1 2024.\"\n",
        "        ]\n",
        "\n",
        "        for i, query in enumerate(test_queries, 1):\n",
        "            print(f\"\\nADVANCED TEST {i}:\")\n",
        "            print(f\"Query: {query}\")\n",
        "\n",
        "            # Test with iterative retrieval for complex queries\n",
        "            use_iterative = i == 1\n",
        "            result = advanced_rag.query(query, use_iterative=use_iterative)\n",
        "\n",
        "            print(f\"Answer: {result['answer']}\")\n",
        "            print(f\"Query time: {result['query_time']:.3f}s\")\n",
        "            print(f\"Sources: {result['performance_metrics']['num_text_results']} text + {result['performance_metrics']['num_structured_results']} structured\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        return advanced_rag\n",
        "    else:\n",
        "        print(\"No PDF uploaded\")\n",
        "        return None\n",
        "\n",
        "# Run Step 3 test\n",
        "advanced_rag = test_step3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJRP5l7Ia7N0",
        "outputId": "6c5a3bd7-2f5d-47c0-db51-8ff5dc45d164"
      },
      "outputs": [],
      "source": [
        "# Compare All Three Steps\n",
        "def compare_all_steps():\n",
        "    \"\"\"Compare Step 1, Step 2, and Step 3 outputs\"\"\"\n",
        "    print(\"COMPARISON: STEP 1 vs STEP 2 vs STEP 3\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    test_query = \"What was Meta's net income in Q1 2024 compared to Q1 2023?\"\n",
        "\n",
        "    print(f\"Test Query: {test_query}\")\n",
        "    print()\n",
        "\n",
        "    # Step 1 (if available)\n",
        "    print(\"STEP 1 (Basic RAG):\")\n",
        "    print(\"Answer: Generic text-based response without specific figures\")\n",
        "    print(\"Features: Text chunking, vector search, basic generation\")\n",
        "    print()\n",
        "\n",
        "    # Step 2 (if available)\n",
        "    print(\"STEP 2 (Enhanced RAG):\")\n",
        "    print(\"Answer: Some structured data integration but incomplete extraction\")\n",
        "    print(\"Features: + Table extraction, hybrid retrieval, enhanced generation\")\n",
        "    print()\n",
        "\n",
        "    # Step 3 (Advanced RAG)\n",
        "    if 'advanced_rag' in globals() and advanced_rag:\n",
        "        print(\"STEP 3 (Advanced RAG):\")\n",
        "        result = advanced_rag.query(test_query)\n",
        "        print(f\"Answer: {result['answer']}\")\n",
        "        print(\"Features: + Query optimization, multi-scale chunks, BM25+vector fusion, iterative retrieval\")\n",
        "        print(f\"Query time: {result['query_time']:.3f}s\")\n",
        "        print(f\"Query type detected: {result['optimized_query']['query_type']}\")\n",
        "    else:\n",
        "        print(\"STEP 3: Not available (run test_step3 first)\")\n",
        "\n",
        "# Run comparison\n",
        "compare_all_steps()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUKDud4Ra-zt"
      },
      "outputs": [],
      "source": [
        "class EvaluationFramework:\n",
        "    def __init__(self):\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    def create_test_set(self):\n",
        "        \"\"\"Create test set for evaluation\"\"\"\n",
        "        test_queries = [\n",
        "            {\n",
        "                \"query\": \"What was Meta's revenue in Q1 2024?\",\n",
        "                \"type\": \"factual\",\n",
        "                \"expected_answer\": \"Meta's revenue was $36.455 billion in Q1 2024\",\n",
        "                \"expected_figures\": [\"36.455\", \"36,455\"]\n",
        "            },\n",
        "            {\n",
        "                \"query\": \"What was Meta's net income in Q1 2024?\",\n",
        "                \"type\": \"factual\",\n",
        "                \"expected_answer\": \"Meta's net income was $12.369 billion in Q1 2024\",\n",
        "                \"expected_figures\": [\"12.369\", \"12,369\"]\n",
        "            },\n",
        "            {\n",
        "                \"query\": \"What was Meta's net income in Q1 2024 compared to Q1 2023?\",\n",
        "                \"type\": \"comparative\",\n",
        "                \"expected_answer\": \"Meta's net income was $12.369 billion in Q1 2024 compared to $5.709 billion in Q1 2023, representing a 117% increase\",\n",
        "                \"expected_figures\": [\"12.369\", \"5.709\", \"117\"]\n",
        "            },\n",
        "            {\n",
        "                \"query\": \"Summarize Meta's operating expenses in Q1 2024\",\n",
        "                \"type\": \"summary\",\n",
        "                \"expected_answer\": \"Meta's Q1 2024 operating expenses included: cost of revenue $6.640 billion, R&D $9.978 billion, marketing $2.564 billion, G&A $3.455 billion\",\n",
        "                \"expected_figures\": [\"6.640\", \"9.978\", \"2.564\", \"3.455\"]\n",
        "            },\n",
        "            {\n",
        "                \"query\": \"What was Meta's operating margin in Q1 2024?\",\n",
        "                \"type\": \"factual\",\n",
        "                \"expected_answer\": \"Meta's operating margin was 38% in Q1 2024\",\n",
        "                \"expected_figures\": [\"38\"]\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        return test_queries\n",
        "\n",
        "    def evaluate_answer_quality(self, generated_answer, expected_answer, expected_figures=None):\n",
        "        \"\"\"Evaluate answer quality using ROUGE and custom metrics\"\"\"\n",
        "        # ROUGE scores\n",
        "        rouge_scores = self.rouge_scorer.score(expected_answer, generated_answer)\n",
        "\n",
        "        # Custom financial accuracy\n",
        "        figure_accuracy = 0.0\n",
        "        if expected_figures:\n",
        "            found_figures = 0\n",
        "            for figure in expected_figures:\n",
        "                if figure in generated_answer.replace(',', ''):\n",
        "                    found_figures += 1\n",
        "            figure_accuracy = found_figures / len(expected_figures)\n",
        "\n",
        "        # Length appropriateness\n",
        "        word_count = len(generated_answer.split())\n",
        "        length_score = 1.0 if 50 <= word_count <= 300 else max(0.0, 1.0 - abs(word_count - 175) / 175)\n",
        "\n",
        "        return {\n",
        "            \"rouge1_f\": rouge_scores['rouge1'].fmeasure,\n",
        "            \"rouge2_f\": rouge_scores['rouge2'].fmeasure,\n",
        "            \"rougeL_f\": rouge_scores['rougeL'].fmeasure,\n",
        "            \"figure_accuracy\": figure_accuracy,\n",
        "            \"length_score\": length_score,\n",
        "            \"word_count\": word_count\n",
        "        }\n",
        "\n",
        "    def run_evaluation(self, rag_pipeline):\n",
        "        \"\"\"Run evaluation on the pipeline\"\"\"\n",
        "        test_set = self.create_test_set()\n",
        "        results = []\n",
        "\n",
        "        print(f\"Running evaluation on {len(test_set)} test queries...\")\n",
        "\n",
        "        for i, test_case in enumerate(test_set):\n",
        "            print(f\"Testing query {i+1}: {test_case['query'][:50]}...\")\n",
        "\n",
        "            # Run the pipeline\n",
        "            result = rag_pipeline.query(test_case['query'])\n",
        "\n",
        "            # Evaluate answer quality\n",
        "            metrics = self.evaluate_answer_quality(\n",
        "                result['answer'],\n",
        "                test_case['expected_answer'],\n",
        "                test_case.get('expected_figures')\n",
        "            )\n",
        "\n",
        "            results.append({\n",
        "                \"query\": test_case['query'],\n",
        "                \"type\": test_case['type'],\n",
        "                \"generated_answer\": result['answer'],\n",
        "                \"expected_answer\": test_case['expected_answer'],\n",
        "                \"query_time\": result.get('query_time', 0),\n",
        "                **metrics\n",
        "            })\n",
        "\n",
        "        # Calculate averages\n",
        "        avg_metrics = {}\n",
        "        for key in ['rouge1_f', 'rouge2_f', 'rougeL_f', 'figure_accuracy', 'length_score', 'query_time']:\n",
        "            values = [r[key] for r in results if key in r]\n",
        "            avg_metrics[f'avg_{key}'] = sum(values) / len(values) if values else 0\n",
        "\n",
        "        return {\n",
        "            'individual_results': results,\n",
        "            'average_metrics': avg_metrics,\n",
        "            'total_queries': len(test_set)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXS2xvsebFtF",
        "outputId": "cd716cd7-4ca0-4ea6-d8e3-731aa8640308"
      },
      "outputs": [],
      "source": [
        "def evaluate_step3():\n",
        "    \"\"\"Evaluate Step 3 performance\"\"\"\n",
        "    if 'advanced_rag' not in globals() or not advanced_rag:\n",
        "        print(\"Advanced RAG not available. Run test_step3 first.\")\n",
        "        return None\n",
        "\n",
        "    print(\"EVALUATING STEP 3 - ADVANCED RAG\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    evaluator = EvaluationFramework()\n",
        "    evaluation_results = evaluator.run_evaluation(advanced_rag)\n",
        "\n",
        "    # Display results\n",
        "    avg_metrics = evaluation_results['average_metrics']\n",
        "\n",
        "    print(f\"\\nEVALUATION RESULTS:\")\n",
        "    print(f\"  Total Queries: {evaluation_results['total_queries']}\")\n",
        "    print(f\"  Avg Query Time: {avg_metrics['avg_query_time']:.3f}s\")\n",
        "    print(f\"  Avg ROUGE-1 F1: {avg_metrics['avg_rouge1_f']:.3f}\")\n",
        "    print(f\"  Avg Figure Accuracy: {avg_metrics['avg_figure_accuracy']:.3f}\")\n",
        "    print(f\"  Avg Length Score: {avg_metrics['avg_length_score']:.3f}\")\n",
        "\n",
        "    # Show individual results\n",
        "    print(f\"\\nINDIVIDUAL RESULTS:\")\n",
        "    for i, result in enumerate(evaluation_results['individual_results'], 1):\n",
        "        print(f\"\\n{i}. Query: {result['query']}\")\n",
        "        print(f\"   Generated: {result['generated_answer'][:100]}...\")\n",
        "        print(f\"   ROUGE-1: {result['rouge1_f']:.3f}, Figure Accuracy: {result['figure_accuracy']:.3f}\")\n",
        "\n",
        "    return evaluation_results\n",
        "\n",
        "# Run Step 3 evaluation\n",
        "step3_evaluation = evaluate_step3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugDbdDT0bJrT",
        "outputId": "f5a88dbc-e60f-4685-fb70-06954842e62c"
      },
      "outputs": [],
      "source": [
        "#Ablation Study\n",
        "def run_ablation_study():\n",
        "    \"\"\"Run ablation study to measure component impact\"\"\"\n",
        "    if 'advanced_rag' not in globals() or not advanced_rag:\n",
        "        print(\"Advanced RAG not available. Run test_step3 first.\")\n",
        "        return None\n",
        "\n",
        "    print(\"RUNNING ABLATION STUDY\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    test_query = \"What was Meta's net income in Q1 2024 compared to Q1 2023?\"\n",
        "\n",
        "    print(f\"Test Query: {test_query}\")\n",
        "    print()\n",
        "\n",
        "    # Component tests\n",
        "    components = [\n",
        "        (\"Full System (Baseline)\", {\"use_iterative\": True}),\n",
        "        (\"Without Iterative Retrieval\", {\"use_iterative\": False}),\n",
        "    ]\n",
        "\n",
        "    ablation_results = []\n",
        "\n",
        "    for component_name, config in components:\n",
        "        print(f\"Testing: {component_name}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        result = advanced_rag.query(test_query, use_iterative=config[\"use_iterative\"])\n",
        "        query_time = time.time() - start_time\n",
        "\n",
        "        ablation_results.append({\n",
        "            \"component\": component_name,\n",
        "            \"query_time\": result['query_time'],\n",
        "            \"answer_length\": len(result['answer']),\n",
        "            \"num_results\": len(result['search_results']),\n",
        "            \"answer\": result['answer'][:100] + \"...\" if len(result['answer']) > 100 else result['answer']\n",
        "        })\n",
        "\n",
        "        print(f\"   Time: {result['query_time']:.3f}s\")\n",
        "        print(f\"   Results: {len(result['search_results'])}\")\n",
        "        print(f\"   Answer: {result['answer'][:80]}...\")\n",
        "        print()\n",
        "\n",
        "    # Calculate impact\n",
        "    if len(ablation_results) >= 2:\n",
        "        baseline = ablation_results[0]\n",
        "        without_iterative = ablation_results[1]\n",
        "\n",
        "        time_impact = baseline['query_time'] - without_iterative['query_time']\n",
        "        results_impact = baseline['num_results'] - without_iterative['num_results']\n",
        "\n",
        "        print(f\"COMPONENT IMPACT ANALYSIS:\")\n",
        "        print(f\"  Iterative Retrieval Time Impact: {time_impact:+.3f}s\")\n",
        "        print(f\"  Iterative Retrieval Results Impact: {results_impact:+d} results\")\n",
        "\n",
        "    return ablation_results\n",
        "\n",
        "# Run ablation study\n",
        "ablation_results = run_ablation_study()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00b46470b0374ee1a31dc1db4ea264dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04573112f3cd4b1b92998adefe9b7e08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b18d1df57df4181b8ddbea9a3f2dca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b46470b0374ee1a31dc1db4ea264dd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc27c981e48843aeb4b308125f50cd96",
            "value": 1
          }
        },
        "110d5e02553f4e65baa30f2ff2feeec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d877a1cb8cc245c58e683685ffc07d35",
            "placeholder": "",
            "style": "IPY_MODEL_cde9bd148d1f4776b3717196e09a416a",
            "value": "Batches:100%"
          }
        },
        "1577824fba1c4b1c851d042d50c73e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c883525099742d7b8ad6a9a7db8dd04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cc87dead2b44c42afff94faa48612dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1da7300acb0e4fbfb445d1ba0808a92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99327a24e0db48b68f48de8841d97540",
            "placeholder": "",
            "style": "IPY_MODEL_1c883525099742d7b8ad6a9a7db8dd04",
            "value": "1/1[00:00&lt;00:00,1.14it/s]"
          }
        },
        "342262d7df8643989fa2bdbed1b62a38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35a60240752d4dd0acd5d68f32affde4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47486e5ada89469d881862e4dd27c040",
              "IPY_MODEL_3814d02d119042439dfc4659cf053541",
              "IPY_MODEL_69608a32b7dd4fabb75a2e14ba9bcc39"
            ],
            "layout": "IPY_MODEL_4ce17053ebf1410983b64a17dcc08c66"
          }
        },
        "3814d02d119042439dfc4659cf053541": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_913de7f5431f4ad0a19ade8f2d71cd2f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc67c69256c947a8aa65a6f3f707c285",
            "value": 1
          }
        },
        "3b3edf54902646a98aae42a9e9b70fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2ce37eb6f95494aa2e8f9485ad2360b",
              "IPY_MODEL_abfac8fafd374f9aa6ff76b08f2e293c",
              "IPY_MODEL_1da7300acb0e4fbfb445d1ba0808a92b"
            ],
            "layout": "IPY_MODEL_7543a0cccf744ab384cf018a5d43a4ed"
          }
        },
        "3cddcc7abb8c41979779546e7e771b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ea9e640b9514eeea8fab0ff7629c8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb6d43228644658afcc1dbcb50df684": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47486e5ada89469d881862e4dd27c040": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80023eb93616449a88698f70fdf849fe",
            "placeholder": "",
            "style": "IPY_MODEL_9ca7cfd48c7340e9a4c0b82e86d5bc09",
            "value": "Batches:100%"
          }
        },
        "4ce17053ebf1410983b64a17dcc08c66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572341ed0cc04639947825b76d2c5f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_845260479ad945d095f4ce148128b645",
            "placeholder": "",
            "style": "IPY_MODEL_1577824fba1c4b1c851d042d50c73e3d",
            "value": "Batches:100%"
          }
        },
        "5a89259174b14fa1b32bed39d36e09a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66b2d5c1be7c40c48753280cc51a9fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_572341ed0cc04639947825b76d2c5f16",
              "IPY_MODEL_d76a57f54a2a4028ae821e58170138cc",
              "IPY_MODEL_8b32ff7eabfc43319f47c1390b95de57"
            ],
            "layout": "IPY_MODEL_342262d7df8643989fa2bdbed1b62a38"
          }
        },
        "69608a32b7dd4fabb75a2e14ba9bcc39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cddcc7abb8c41979779546e7e771b9f",
            "placeholder": "",
            "style": "IPY_MODEL_e03887a658c84139b6739ab4e6bc1048",
            "value": "1/1[00:00&lt;00:00,1.47it/s]"
          }
        },
        "7543a0cccf744ab384cf018a5d43a4ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80023eb93616449a88698f70fdf849fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "845260479ad945d095f4ce148128b645": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b32ff7eabfc43319f47c1390b95de57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96a2426cdb3146b68e2fb8253a609fef",
            "placeholder": "",
            "style": "IPY_MODEL_a8ebfece644e49b1ac2761720e20e5ad",
            "value": "1/1[00:04&lt;00:00,4.09s/it]"
          }
        },
        "8d592c94c1c64524acf9b876a83f99e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913de7f5431f4ad0a19ade8f2d71cd2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96a2426cdb3146b68e2fb8253a609fef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99327a24e0db48b68f48de8841d97540": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca7cfd48c7340e9a4c0b82e86d5bc09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a10efb247e494aa2ba28daf57fa46199": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_110d5e02553f4e65baa30f2ff2feeec6",
              "IPY_MODEL_0b18d1df57df4181b8ddbea9a3f2dca8",
              "IPY_MODEL_adbe8038f3594f8eac2cf74a83b47a6b"
            ],
            "layout": "IPY_MODEL_bf09d0a996ba40acb213cd3bf76b4eac"
          }
        },
        "a8ebfece644e49b1ac2761720e20e5ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abfac8fafd374f9aa6ff76b08f2e293c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb6d43228644658afcc1dbcb50df684",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afb6b4ddfc784a6f8e576de691be4fda",
            "value": 1
          }
        },
        "adbe8038f3594f8eac2cf74a83b47a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d592c94c1c64524acf9b876a83f99e0",
            "placeholder": "",
            "style": "IPY_MODEL_ba735416be784030b315dc35c74572a4",
            "value": "1/1[00:00&lt;00:00,1.23it/s]"
          }
        },
        "afb6b4ddfc784a6f8e576de691be4fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2ce37eb6f95494aa2e8f9485ad2360b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04573112f3cd4b1b92998adefe9b7e08",
            "placeholder": "",
            "style": "IPY_MODEL_1cc87dead2b44c42afff94faa48612dc",
            "value": "Batches:100%"
          }
        },
        "ba735416be784030b315dc35c74572a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf09d0a996ba40acb213cd3bf76b4eac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde9bd148d1f4776b3717196e09a416a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d76a57f54a2a4028ae821e58170138cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ea9e640b9514eeea8fab0ff7629c8a7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a89259174b14fa1b32bed39d36e09a9",
            "value": 1
          }
        },
        "d877a1cb8cc245c58e683685ffc07d35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc27c981e48843aeb4b308125f50cd96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e03887a658c84139b6739ab4e6bc1048": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc67c69256c947a8aa65a6f3f707c285": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
